# ðŸš€ SUPER NOVA RAG ðŸš€

## Overview

Hybrid Retrieval-Augmented Generation (RAG) pipeline.

## Pipeline

1. **Chunking by row (*.csv)**
    - add summary column: `combined_info`
    - column `_id` for benchmark only

```bash
python src/chunk_docs_neo4j.py --file src/file_paths.txt 
```

2. **Ensemble: BM25 + Embedding (Qwen3-0.6B / Qwen3-8B)**
    - Todo: BM25 for Vietnamese documents
1. **Reranker**
    - Qwen3-0.6B-Reranker: broken!
    - BAAI/bge-reranker-v2-m3

> ðŸ”¹ BM25 removed in benchmark to measure *pure embedding performance*.  

## Benchmark: top 100 embedding (Qwen3-8B) -> top (1,5,20) reranking (bge-reranker-v2-m3)

```bash
Final scores: {'hit@1': 0.88125, 'hit@5': 0.98125, 'hit@20': 1.0, 'missed': []}
```

## Benchmark: embedding only (Qwen3-0.6B) (no rerank)

```bash
Final scores:
{'hit@1': 0.653125, 'hit@5': 0.9, 'hit@10': 0.940625, 'missed': [{'id': '666baeb59793e149fe7393e5', 'query': 'TÃ´i muá»‘n mua Ä‘iá»‡n thoáº¡i ai, bÃªn báº¡n cÃ²n hÃ ng khÃ´ng?', 'expected': 'Ä‘iá»‡n thoáº¡i ai'}, {'id': '666baeb59793e149fe7393e3', 'query': 'TÃ´i muá»‘n mua Ä‘iá»‡n thoáº¡i ai, bÃªn báº¡n cÃ²n hÃ ng khÃ´ng?', 'expected': 'Ä‘iá»‡n thoáº¡i ai'}, {'id': '666baeb59793e149fe7393e4', 'query': 'TÃ´i muá»‘n mua Ä‘iá»‡n thoáº¡i ai, bÃªn báº¡n cÃ²n hÃ ng khÃ´ng?', 'expected': 'Ä‘iá»‡n thoáº¡i ai'}, {'id': '666baeb59793e149fe7393e2', 'query': 'TÃ´i Ä‘ang quan tÃ¢m Ä‘áº¿n Ä‘iá»‡n thoáº¡i ai, báº¡n cÃ³ thá»ƒ tÆ° váº¥n thÃªm cho tÃ´i khÃ´ng?', 'expected': 'Ä‘iá»‡n thoáº¡i ai'}, {'id': '666baeb59793e149fe7393ec', 'query': 'TÃ´i muá»‘n mua Ä‘iá»‡n thoáº¡i ai, bÃªn báº¡n cÃ²n hÃ ng khÃ´ng?', 'expected': 'Ä‘iá»‡n thoáº¡i ai'}, {'id': '666baeb59793e149fe7393ed', 'query': 'TÃ´i Ä‘ang quan tÃ¢m Ä‘áº¿n Ä‘iá»‡n thoáº¡i ai, báº¡n cÃ³ thá»ƒ tÆ° váº¥n thÃªm cho tÃ´i khÃ´ng?', 'expected': 'Ä‘iá»‡n thoáº¡i ai'}, {'id': '666baeb59793e149fe7393f2', 'query': 'Ä‘iá»‡n thoáº¡i zte blade v50 design (8gb/256gb) cÃ³ mÃ u nÃ o vÃ  dung lÆ°á»£ng bao nhiÃªu GB váº­y?', 'expected': 'Ä‘iá»‡n thoáº¡i zte blade v50 design (8gb/256gb)'}, {'id': '666baeb89793e149fe7394a2', 'query': 'TÃ´i muá»‘n Ä‘áº·t mua Ä‘iá»‡n thoáº¡i Ä‘iá»‡n thoáº¡i di Ä‘á»™ng xor x2 prime gold, cáº§n lÃ m tháº¿ nÃ o?', 'expected': 'Ä‘iá»‡n thoáº¡i Ä‘iá»‡n thoáº¡i di Ä‘á»™ng xor x2 prime gold'}, {'id': '666baeb89793e149fe7394a5', 'query': 'Cho tÃ´i há»i Ä‘iá»‡n thoáº¡i oppo a16k 3gb/32gb hiá»‡n táº¡i giÃ¡ bao nhiÃªu?', 'expected': 'Ä‘iá»‡n thoáº¡i oppo a16k 3gb/32gb'}, {'id': '666baeb89793e149fe7394b4', 'query': 'Ä‘iá»‡n thoáº¡i samsung galaxy a02s 4gb/64gb cÃ³ mÃ u nÃ o vÃ  dung lÆ°á»£ng bao nhiÃªu GB váº­y?', 'expected': 'Ä‘iá»‡n thoáº¡i samsung galaxy a02s 4gb/64gb'}, {'id': '666baeb89793e149fe7394b0', 'query': 'Cho tÃ´i há»i oppo a54 hiá»‡n táº¡i giÃ¡ bao nhiÃªu?', 'expected': 'oppo a54'}, {'id': '666baeb99793e149fe7394d3', 'query': 'Cho tÃ´i há»i oppo reno4 pro hiá»‡n táº¡i giÃ¡ bao nhiÃªu?', 'expected': 'oppo reno4 pro'}, {'id': '666baeb99793e149fe7394cf', 'query': 'TÃ´i muá»‘n mua Ä‘iá»‡n thoáº¡i samsung galaxy z fold2 5g, bÃªn báº¡n cÃ²n hÃ ng khÃ´ng?', 'expected': 'Ä‘iá»‡n thoáº¡i samsung galaxy z fold2 5g'}, {'id': '666baeb99793e149fe7394d1', 'query': 'Cho tÃ´i há»i Ä‘iá»‡n thoáº¡i energizer e241s hiá»‡n táº¡i giÃ¡ bao nhiÃªu?', 'expected': 'Ä‘iá»‡n thoáº¡i energizer e241s'}, {'id': '666baeb99793e149fe7394d4', 'query': 'TÃ´i muá»‘n mua oppo reno4, bÃªn báº¡n cÃ²n hÃ ng khÃ´ng?', 'expected': 'oppo reno4'}, {'id': '666baeb99793e149fe7394dd', 'query': 'TÃ´i muá»‘n mua Ä‘iá»‡n thoáº¡i samsung galaxy s20 ultra, bÃªn báº¡n cÃ²n hÃ ng khÃ´ng?', 'expected': 'Ä‘iá»‡n thoáº¡i samsung galaxy s20 ultra'}, {'id': '666baeb99793e149fe7394de', 'query': 'Cho tÃ´i há»i Ä‘iá»‡n thoáº¡i samsung galaxy s20 hiá»‡n táº¡i giÃ¡ bao nhiÃªu?', 'expected': 'Ä‘iá»‡n thoáº¡i samsung galaxy s20'}, {'id': '666baeb99793e149fe7394d7', 'query': 'Cho tÃ´i há»i oppo a53 hiá»‡n táº¡i giÃ¡ bao nhiÃªu?', 'expected': 'oppo a53'}, {'id': '666baeb99793e149fe7394e0', 'query': 'Cho tÃ´i há»i Ä‘á»“ng há»“ thÃ´ng minh samsung galaxy fit e (sm hiá»‡n táº¡i giÃ¡ bao nhiÃªu?', 'expected': 'Ä‘á»“ng há»“ thÃ´ng minh samsung galaxy fit e (sm'}]}
```

## Benchmark: top 50 embedding (Qwen3-0.6B) -> top (1,5,10) reranking (bge-reranker-v2-m3)

- **Dataset**: 320 records (src\data\hoanghamobile_with_summary.csv)
- **Mode**: Embedding-only retrieval
- **Metric**: `hit@k` (1, 5, 10)

```bash
Final scores:
{'hit@1': 0.85625, 'hit@5': 0.978125, 'hit@10': 0.978125, 'missed': [{'id': '666baeb59793e149fe7393e5', 'query': 'Cho tÃ´i há»i Ä‘iá»‡n thoáº¡i ai hiá»‡n táº¡i giÃ¡ bao nhiÃªu?', 'expected': 'Ä‘iá»‡n thoáº¡i ai'}, {'id': '666baeb59793e149fe7393e4', 'query': 'Cho tÃ´i há»i Ä‘iá»‡n thoáº¡i ai hiá»‡n táº¡i giÃ¡ bao nhiÃªu?', 'expected': 'Ä‘iá»‡n thoáº¡i ai'}, {'id': '666baeb59793e149fe7393e2', 'query': 'TÃ´i muá»‘n mua Ä‘iá»‡n thoáº¡i ai, bÃªn báº¡n cÃ²n hÃ ng khÃ´ng?', 'expected': 'Ä‘iá»‡n thoáº¡i ai'}, {'id': '666baeb59793e149fe7393ec', 'query': 'Cho tÃ´i há»i Ä‘iá»‡n thoáº¡i ai hiá»‡n táº¡i giÃ¡ bao nhiÃªu?', 'expected': 'Ä‘iá»‡n thoáº¡i ai'}, {'id': '666baeb79793e149fe739457', 'query': 'TÃ´i muá»‘n Ä‘áº·t mua Ä‘iá»‡n thoáº¡i samsung galaxy s23, cáº§n lÃ m tháº¿ nÃ o?', 'expected': 'Ä‘iá»‡n thoáº¡i samsung galaxy s23'}, {'id': '666baeb79793e149fe739462', 'query': 'Cho tÃ´i há»i vivo v25 pro 8gb/128gb hiá»‡n táº¡i giÃ¡ bao nhiÃªu?', 'expected': 'vivo v25 pro 8gb/128gb'}, {'id': '666baeb99793e149fe7394d8', 'query': 'Cho tÃ´i há»i oppo a12 hiá»‡n táº¡i giÃ¡ bao nhiÃªu?', 'expected': 'oppo a12'}]}
```

## Benchmark: top 50 embedding (Qwen3-0.6B) + 50 BM25 (dedup) -> top (1,5,20) reranking (bge-reranker-v2-m3)

```bash
Final scores: 
{'hit@1': 0.86875, 'hit@5': 0.96875, 'hit@20': 0.996875, 'missed': [{'id': '666baeb79793e149fe739450', 'query': 'TÃ´i Ä‘ang quan tÃ¢m Ä‘áº¿n realme c55, báº¡n cÃ³ thá»ƒ tÆ° váº¥n thÃªm cho tÃ´i khÃ´ng?', 'expected': 'realme c55'}]}
```

## âš™ï¸ Setup & Run (with uv)

```bash
pip install uv
uv pip install -r requirements.txt --index-strategy unsafe-best-match
```

Run the MCP server

```bash
uv run uvicorn src.mcp_server:app --host 0.0.0.0 --port 8000 --reload
```

## Docker

```bash
bash run_docker.sh
```

neo4j web: localhost:7474

## ðŸ”‘ Environment Configuration (.env)

Create a `.env` file in the project root with the following variables:

```bash
# Embedding service (Qwen3-0.6B)
# openai compatible
OPENAI_BASE_URL_EMBED=http://localhost:8080/v1
OPENAI_API_KEY_EMBED=dummy_text
# for vllm: Qwen/Qwen3-Embedding-0.6B
OPENAI_API_MODEL_NAME_EMBED=Qwen/Qwen3-Embedding-0.6B
# 1024 for Qwen3-0.6B
EMBED_DIM=1024

# Reranker service (BGE-Reranker)
OPENAI_BASE_URL_RERANK=http://localhost:8081
OPENAI_API_KEY_RERANK=dummy_text
# for vllm: BAAI/bge-reranker-v2-m3
OPENAI_API_MODEL_NAME_RERANK=BAAI/bge-reranker-v2-m3

# Neo4j database
# docker network, docker compose config
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=12345678
NEO4J_DATABASE=neo4j
```

## VLLM localhost embedding & reranker

```yaml
services:
  embedding-service:
    image: vllm/vllm-openai:latest
    container_name: vllm-qwen3-embedding
    network_mode: host
    runtime: nvidia
    # environment:
    #   - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}  # Optional: Your HF token
    volumes:
      - ./models:/models  # Cache models
    ipc: host  # Shared memory for PyTorch/vLLM

    # --enforce-eager  Optional: For debugging; disable for better perf
    command: >
      --model Qwen/Qwen3-Embedding-0.6B
      --task embed
      --dtype float16
      --max-model-len 8192
      --host 0.0.0.0
      --port 8080
      --enforce-eager
      --gpu-memory-utilization 0.45
      --hf_overrides '{"matryoshka_dimensions":[1024]}'
    # restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
  bge-reranker:
    image: vllm/vllm-openai:latest
    container_name: vllm-bge-reranker
    network_mode: host
    runtime: nvidia
    # environment:
    #   - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}  # Optional: Your HF token
    volumes:
      - ./models:/models  # Cache models
    ipc: host  # Shared memory for PyTorch/vLLM
    command: >
      --model BAAI/bge-reranker-v2-m3
      --task score
      --dtype float16
      --max-model-len 8192
      --host 0.0.0.0
      --port 8081
      --enforce-eager
      --gpu-memory-utilization 0.3
    # restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
  ### Qwen3-0.6B-Reranker broken!
  # reranker-service:
  #   image: vllm/vllm-openai:latest
  #   container_name: vllm-qwen3-reranker
  #   network_mode: host
  #   runtime: nvidia
  #   # environment:
  #   #   - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}  # Optional: Your HF token
  #   volumes:
  #     - ./models:/models  # Cache models
  #   ipc: host  # Shared memory for PyTorch/vLLM
  #   command: >
  #     --model Qwen/Qwen3-Reranker-0.6B
  #     --task score
  #     --dtype float16
  #     --max-model-len 8192
  #     --port 8081
  #     --hf_overrides '{"architectures": ["Qwen3ForSequenceClassification"],"classifier_from_token": ["no", "yes"],"is_original_qwen3_reranker": true}'
  #     --enforce-eager
  #     --gpu-memory-utilization 0.45
  #   # restart: unless-stopped
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: all
  #             capabilities: [gpu]
```